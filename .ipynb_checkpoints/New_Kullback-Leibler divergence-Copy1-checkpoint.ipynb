{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09473dd-456f-4a7e-bcc6-70cdbb947d91",
   "metadata": {},
   "source": [
    "**THis is an updated version of how the KL Divergence is computed and how the trees are trained. It makes use of parallel processing and the syntax has been simplified.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30acac8a-62fb-4d2f-9f9d-46471e60ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sympy \n",
    "import matplotlib as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from copy import deepcopy\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append('./')\n",
    "sys.path.append('./Prior/')\n",
    "from mcmc import *\n",
    "from parallel import *\n",
    "from fit_prior import read_prior_par\n",
    "\n",
    "#File related libraries\n",
    "from expression_writter import *\n",
    "\n",
    "#Writing files libraries\n",
    "import re\n",
    "from file_creator import *\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "#librarires for parallel processing\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d9d41b-d8f1-47f4-bc3e-cad0a2150bfc",
   "metadata": {},
   "source": [
    "Adding the file of a function to be studied. Several functions will be repeated and we will only count them onece, so we first have to filter that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1409f9c9-378c-43b7-b000-211819c0f420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         abs(sin(exp(_a18_)))\n",
       "1    log(sin((_a1_ ** _a11_)))\n",
       "2          pow2(pow3(pow2(x)))\n",
       "3          -(abs(sinh(_a18_)))\n",
       "4        (cosh(_a16_) * _a16_)\n",
       "Name: expression, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./New_Experiment/Training_Datasets/Prob_Comparison_sin(1.5*x)*cos(0.5*z).csv\")\n",
    "desc_lengths, expressions, neg_log_probs = df['bms_E'], df['expression'], df['minus_log_prob_tree']\n",
    "expressions = expressions.str.strip()\n",
    "expressions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f483c0c-a90f-49bf-a846-559aa762dd6e",
   "metadata": {},
   "source": [
    "Variables and parameters config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca260d44-e9e6-407d-a21d-83011afc111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XLABS = ['x', 'z'] #Change to just x if one variable models\n",
    "parameters = ['_a%d_' % i for i in range(20)]\n",
    "\n",
    "#creating empty tree and probtree\n",
    "model = Tree(\n",
    "    variables = XLABS,\n",
    "    parameters = parameters,\n",
    ")\n",
    "\n",
    "#Probability tree\n",
    "Tree_prob =ProbTree(\n",
    "    tree = model,\n",
    "    variables = XLABS,\n",
    "    parameters = parameters,\n",
    ") \n",
    "\n",
    "#name of the file where the prob_tree will be stored\n",
    "objFile = \"./New_Experiment/Prob_Trees/Prob_Tree_sin(1.5*x)*cos(0.5*z)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed693e3-85d9-4775-a62e-da3b6a142d8c",
   "metadata": {},
   "source": [
    "### Parallelized version of the KL Divergence computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2f7ba5-ac3f-4ef8-a18a-4a0f4585387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8627144748388686e+153\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor \n",
    "## Función process_batch a nivel de módulo (requerido para paralelización)\n",
    "def process_batch(args):\n",
    "    \"\"\"\n",
    "    Processes a data batch and computes its contribution to the KL Divergence\n",
    "    Args: (desc_batch, expr_batch, probTree)\n",
    "    \"\"\"\n",
    "    desc_batch, expr_batch, probTree = args\n",
    "    batch_results = []\n",
    "    \n",
    "    for desc_length, expression in zip(desc_batch, expr_batch):\n",
    "        # Build the tree atribute in prob tree for each expression\n",
    "        probTree.tree.build_from_string(expression)\n",
    "        exp_prob_tree = probTree.pr_tree()\n",
    "        #print(exp_prob_tree)\n",
    "        contribution = -np.exp(-desc_length) * (desc_length + np.log(exp_prob_tree))\n",
    "        if np.isinf(contribution):\n",
    "            print(\"The contribution is infinite\")\n",
    "            print(f\"desc length: {desc_length}\")\n",
    "            print(f\"prob expression = {exp_prob_tree}\")\n",
    "            print(f\"expression : {expression}\")\n",
    "        batch_results.append(contribution)\n",
    "    return np.sum(batch_results) if batch_results else 0\n",
    "\n",
    "def KLDivergence_optimized(\n",
    "    desc_length_df,\n",
    "    expression_df,\n",
    "    probTree,\n",
    "    n_workers=None,\n",
    "    batch_size=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Versión optimizada para DataFrames con paralelización\n",
    "    \"\"\"\n",
    "\n",
    "    # Validación de inputs\n",
    "    assert len(desc_length_df) == len(expression_df), \"DataFrames deben tener el mismo tamaño\"\n",
    "    \n",
    "    # Convertimos a listas para procesamiento eficiente\n",
    "    desc_lengths_list = desc_length_df.tolist()\n",
    "    expressions_list = expression_df.tolist()\n",
    "    \n",
    "    # Configuración de paralelización\n",
    "    n_workers = n_workers or max(1, mp.cpu_count() - 1)\n",
    "    \n",
    "    # Creación de lotes con todos los parámetros necesarios\n",
    "    batch_args = [\n",
    "        (\n",
    "            desc_lengths_list[i:i+batch_size], \n",
    "            expressions_list[i:i+batch_size],\n",
    "            probTree\n",
    "        )\n",
    "        for i in range(0, len(desc_lengths_list), batch_size)\n",
    "    ]\n",
    "    \n",
    "    # Procesamiento paralelo\n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        results = list(executor.map(process_batch, batch_args))\n",
    "   \n",
    "    return sum(results)\n",
    "\n",
    "\n",
    "KL = KLDivergence_optimized(\n",
    "    desc_length_df = desc_lengths,\n",
    "    expression_df = expressions,\n",
    "    probTree = Tree_prob,\n",
    "    n_workers=None,\n",
    "    batch_size=1000\n",
    ")\n",
    "print(KL)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e1cd9c-1ffa-4b1a-a550-b2b4fd4a51dc",
   "metadata": {},
   "source": [
    "Now, a copy of the current Probability Tree will be walked through and the probabilites of a node chosen at random will be changed (the other probabilites will be accordingly adapted). Then, the KL Divergence will be computed again, and if its value is smaller then the change will be accepted, otherwise rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb00804-08ca-477f-84d0-2933a8eaf4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial KL Divergence: 3.8627144748388686e+153\n"
     ]
    }
   ],
   "source": [
    "##### Kullback-Leibler Divergence random improvement\n",
    "def KL_improve(Tree_prob, D):\n",
    "    Tree_copy = Tree_prob.tree_copy()\n",
    "    Tree_copy.modify_random_prob()\n",
    "    newD = KLDivergence_optimized(\n",
    "        desc_length_df = desc_lengths,\n",
    "        expression_df = expressions,\n",
    "        probTree=Tree_copy\n",
    "    )\n",
    "    #newD = KLDivergence(filepath= newPath, probTree=Tree_copy)\n",
    "    if newD < D:\n",
    "        D = newD\n",
    "        Tree_prob = Tree_copy #replace with the better prob tree        \n",
    "    return D, Tree_prob, newD #record all values that are achieved with this procedure, and update the tree in case of improvement       \n",
    "D = KLDivergence_optimized(desc_length_df = desc_lengths, expression_df=expressions, probTree = Tree_prob)\n",
    "print(\"Initial KL Divergence: \" + str(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22c4cc-cd5f-4d51-97dc-71d45c2590de",
   "metadata": {},
   "source": [
    "Files with the evolution of the KL Divergence will be saved and stored in the folder named `KL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a12828-0dbf-493a-948b-e341fe2efa58",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570b78846e394d37b06729c9f98cd7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Running:', max=25000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 25000\n",
    "initialD = D\n",
    "KL_evolution_filepath = \"./New_Experiment/KL Evolution/KL_Evolution_sin(1.5*x)*cos(0.5*z).txt\"\n",
    "with open(KL_evolution_filepath, 'w') as f:\n",
    "    f.write(f\"{D}\\n\")\n",
    "    bar = IntProgress(min = 0, max = N, description='Running:')\n",
    "    display(bar)\n",
    "    for i in range(0,N):\n",
    "        D, Tree_prob, newD =  KL_improve(Tree_prob = Tree_prob, D = D)\n",
    "        f.write(f\"{newD}\\n\")\n",
    "        bar.value += 1\n",
    "        if i % 1000 == 0:\n",
    "            f.flush()\n",
    "            #Now we add the last probability tree we have\n",
    "            with open(objFile, 'wb') as file:\n",
    "                pickle.dump(Tree_prob, file)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e551367-6bd6-41b7-9ac3-9ba29ee127c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_prob.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a2c40-e907-4b6b-8f28-9f4be6e1778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we add the last probability tree we have\n",
    "with open(objFile, 'wb') as f:\n",
    "    pickle.dump(Tree_prob, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706f3e0-5f3a-46bf-acc4-cc18e66b263a",
   "metadata": {},
   "source": [
    "Plot the evolution of the KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e0d15-b000-4cb3-8b68-3320ce6469fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(0,N+1,1)\n",
    "KL = []\n",
    "\n",
    "with open(KL_evolution_filepath, 'r') as f:\n",
    "    for line in f:\n",
    "        KL.append(float(line.strip()))\n",
    "\n",
    "steps = np.arange(0,len(KL),1)\n",
    "\n",
    "title = \"KL Divergence evolution of sin(1.5*x)*cos(0.5*z)\"\n",
    "output_folder = \"./New_Experiment/Figures/\"\n",
    "output_filename = f\"KL_Evolution_sin(1.5*x)*cos(0.5*z).png\"\n",
    "output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "plt.figure(figsize = (4,3))\n",
    "plt.plot(steps, KL, label=\"KL Divergence\", color=\"blue\")\n",
    "plt.xlabel(\"Steps\", fontsize=14)\n",
    "plt.ylabel(\"KL\", fontsize=14)\n",
    "plt.title(title, fontsize=16, pad=20)\n",
    "plt.legend(loc=\"best\", fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.savefig(output_path, dpi = 150, bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e88a7b-dd73-498a-b83a-83ea4bdb5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_prob.tree.build_from_string(\"(sin(pow2(cos(_a6_))) + cos(tanh((_a3_ + x))))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f721a-39fc-45eb-b115-700559e9cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_prob.root.prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67cf383-d7ad-43ce-8afb-e7c396ccef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2250738585072014e-308\n"
     ]
    }
   ],
   "source": [
    "Tree_prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc933ecd-9119-4322-86ad-661b5d862f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
